{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886be447-44cb-4682-9da9-cfd8887da129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols  # type: ignore\n",
    "from statsmodels.stats.anova import anova_lm  # type: ignore\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from embedding_utils import (\n",
    "    load_embeddings,\n",
    "    extract_llm_human_similarities_for_anova,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed49a3-ce70-40c5-abe0-146f5b7aed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "all_embeddings = {\n",
    "    \"Base\": load_embeddings(\"../data/embeddings.csv\"),\n",
    "    \"Portuguese\": load_embeddings(\"../data/embeddings_br.csv\"),\n",
    "    \"German\": load_embeddings(\"../data/embeddings_de.csv\"),\n",
    "    \"Spanish\": load_embeddings(\"../data/embeddings_es.csv\"),\n",
    "    \"French\": load_embeddings(\"../data/embeddings_fr.csv\"),\n",
    "}\n",
    "\n",
    "language_codes = [\"Base\", \"Portuguese\", \"German\", \"Spanish\", \"French\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e91d2-ad52-4340-aac5-d74ed1d15bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing languages: 100%|██████████| 5/5 [00:42<00:00,  8.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "df_anova = extract_llm_human_similarities_for_anova(all_embeddings, language_codes)\n",
    "df_anova = df_anova[\n",
    "    ~df_anova[\"actor1\"].isin([\"gemini\", \"bison\"])\n",
    "]  # Remove Gemini and Bison from analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb9e71-96ec-4c2a-b6d6-2e101d7ff5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "output_file = \"../results/anova_data.csv\"\n",
    "df_anova.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f07919-d8df-4703-8a6e-90297dfd220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DESCRIPTIVE STATISTICS ===\n",
      "\n",
      "By Actor (LLM + reasoning type):\n",
      "           count      mean       std       min       25%       50%       75%  \\\n",
      "actor1                                                                         \n",
      "claude   35200.0  0.443907  0.149189 -0.093526  0.344198  0.457664  0.553225   \n",
      "gemma    56812.0  0.412250  0.147336 -0.123496  0.312816  0.420206  0.518762   \n",
      "gpt3.5   35200.0  0.431731  0.152288 -0.157070  0.327947  0.441166  0.544672   \n",
      "gpt4     24394.0  0.449698  0.161081 -0.112287  0.340416  0.461528  0.566727   \n",
      "llama    35200.0  0.398551  0.169290 -0.193726  0.294246  0.418923  0.522491   \n",
      "mistral  35200.0  0.390742  0.158669 -0.131123  0.283102  0.400584  0.506198   \n",
      "\n",
      "              max  \n",
      "actor1             \n",
      "claude   0.884231  \n",
      "gemma    0.841023  \n",
      "gpt3.5   0.874765  \n",
      "gpt4     0.904920  \n",
      "llama    0.852901  \n",
      "mistral  0.856723  \n",
      "\n",
      "By Language:\n",
      "               count      mean       std       min       25%       50%  \\\n",
      "language                                                                 \n",
      "Base        205314.0  0.425012  0.152372 -0.157070  0.322252  0.434628   \n",
      "French        5076.0  0.353640  0.178640 -0.155702  0.257711  0.398921   \n",
      "German        6192.0  0.239125  0.147519 -0.193726  0.146658  0.256916   \n",
      "Portuguese    3960.0  0.462688  0.164470 -0.093318  0.402972  0.499219   \n",
      "Spanish       1464.0  0.428494  0.183183 -0.125831  0.358011  0.468472   \n",
      "\n",
      "                 75%       max  \n",
      "language                        \n",
      "Base        0.536226  0.904920  \n",
      "French      0.477292  0.781536  \n",
      "German      0.338655  0.711157  \n",
      "Portuguese  0.572480  0.814004  \n",
      "Spanish     0.552486  0.820394  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(\"\\nBy Actor (LLM + reasoning type):\")\n",
    "print(df_anova.groupby(\"actor1\")[\"similarity\"].describe())\n",
    "\n",
    "print(\"\\nBy Language:\")\n",
    "print(df_anova.groupby(\"language\")[\"similarity\"].describe())\n",
    "\n",
    "# # %%\n",
    "# print(\"\\n=== ONE-WAY ANOVA: Comparing Actors ===\")\n",
    "# actor_model = ols(\"similarity ~ C(actor1)\", data=df_anova).fit()\n",
    "# actor_anova_table = anova_lm(actor_model, typ=2)\n",
    "# print(actor_anova_table)\n",
    "\n",
    "# # %%\n",
    "# print(\"\\n=== ONE-WAY ANOVA: Comparing Languages ===\")\n",
    "# language_model = ols(\"similarity ~ C(language)\", data=df_anova).fit()\n",
    "# language_anova_table = anova_lm(language_model, typ=2)\n",
    "# print(language_anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5470b-fb09-408f-acab-b1d482f50e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TWO-WAY ANOVA: Actor × Language ===\n",
      "                            sum_sq        df            F  PR(>F)\n",
      "C(actor1)               102.718378       5.0   919.657495     0.0\n",
      "C(language)             243.908706       4.0  2729.702238     0.0\n",
      "C(actor1):C(language)   158.380327      20.0   354.502420     0.0\n",
      "Residual               4958.588359  221976.0          NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\n=== TWO-WAY ANOVA: Actor × Language ===\")\n",
    "model = ols(\"similarity ~ C(actor1) * C(language)\", data=df_anova).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed5cb0-0b9a-4efe-8677-6ca76faad08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== POST-HOC TEST: Tukey's HSD ===\n",
      "            group1             group2  meandiff  p-adj   lower   upper  reject\n",
      "       claude_Base      claude_French    0.0226 0.0000  0.0081  0.0372    True\n",
      "       claude_Base      claude_German   -0.1352 0.0000 -0.1499 -0.1204    True\n",
      "       claude_Base  claude_Portuguese    0.0980 0.0000  0.0799  0.1160    True\n",
      "       claude_Base     claude_Spanish    0.0828 0.0000  0.0545  0.1110    True\n",
      "       claude_Base         gemma_Base   -0.0303 0.0000 -0.0348 -0.0257    True\n",
      "       claude_Base        gpt3.5_Base   -0.0128 0.0000 -0.0180 -0.0076    True\n",
      "       claude_Base          gpt4_Base    0.0079 0.0000  0.0019  0.0140    True\n",
      "       claude_Base         llama_Base   -0.0242 0.0000 -0.0293 -0.0192    True\n",
      "       claude_Base       mistral_Base   -0.0439 0.0000 -0.0490 -0.0387    True\n",
      "     claude_French      claude_German   -0.1578 0.0000 -0.1779 -0.1378    True\n",
      "     claude_French  claude_Portuguese    0.0753 0.0000  0.0528  0.0979    True\n",
      "     claude_French     claude_Spanish    0.0601 0.0000  0.0289  0.0913    True\n",
      "     claude_French       gemma_French   -0.0772 0.0000 -0.0974 -0.0569    True\n",
      "     claude_French      gpt3.5_French   -0.0194 0.0097 -0.0395  0.0007   False\n",
      "     claude_French        gpt4_French   -0.0140 0.3922 -0.0343  0.0064   False\n",
      "     claude_French       llama_French   -0.3854 0.0000 -0.4069 -0.3640    True\n",
      "     claude_French     mistral_French   -0.1876 0.0000 -0.2174 -0.1579    True\n",
      "     claude_German  claude_Portuguese    0.2331 0.0000  0.2105  0.2558    True\n",
      "     claude_German     claude_Spanish    0.2179 0.0000  0.1866  0.2492    True\n",
      "     claude_German       gemma_German   -0.0283 0.0000 -0.0476 -0.0090    True\n",
      "     claude_German      gpt3.5_German    0.0077 0.9985 -0.0124  0.0279   False\n",
      "     claude_German        gpt4_German   -0.0007 1.0000 -0.0210  0.0196   False\n",
      "     claude_German       llama_German   -0.2731 0.0000 -0.2915 -0.2548    True\n",
      "     claude_German     mistral_German   -0.1293 0.0000 -0.1527 -0.1059    True\n",
      " claude_Portuguese     claude_Spanish   -0.0152 0.9731 -0.0481  0.0177   False\n",
      " claude_Portuguese   gemma_Portuguese   -0.0995 0.0000 -0.1230 -0.0759    True\n",
      " claude_Portuguese  gpt3.5_Portuguese   -0.0078 1.0000 -0.0322  0.0167   False\n",
      " claude_Portuguese    gpt4_Portuguese   -0.0056 1.0000 -0.0301  0.0189   False\n",
      " claude_Portuguese   llama_Portuguese   -0.1883 0.0000 -0.2287 -0.1480    True\n",
      " claude_Portuguese mistral_Portuguese   -0.1800 0.0000 -0.2177 -0.1423    True\n",
      "    claude_Spanish      gemma_Spanish   -0.1032 0.0000 -0.1433 -0.0631    True\n",
      "    claude_Spanish     gpt3.5_Spanish   -0.0020 1.0000 -0.0413  0.0373   False\n",
      "    claude_Spanish       gpt4_Spanish   -0.0124 1.0000 -0.0517  0.0269   False\n",
      "    claude_Spanish      llama_Spanish   -0.3234 0.0000 -0.3896 -0.2572    True\n",
      "    claude_Spanish    mistral_Spanish   -0.1541 0.0000 -0.2144 -0.0938    True\n",
      "        gemma_Base       gemma_French   -0.0243 0.0000 -0.0391 -0.0094    True\n",
      "        gemma_Base       gemma_German   -0.1332 0.0000 -0.1465 -0.1199    True\n",
      "        gemma_Base   gemma_Portuguese    0.0288 0.0000  0.0128  0.0447    True\n",
      "        gemma_Base      gemma_Spanish    0.0098 0.9998 -0.0195  0.0392   False\n",
      "        gemma_Base        gpt3.5_Base    0.0175 0.0000  0.0128  0.0221    True\n",
      "        gemma_Base          gpt4_Base    0.0382 0.0000  0.0326  0.0438    True\n",
      "        gemma_Base         llama_Base    0.0060 0.0000  0.0015  0.0105    True\n",
      "        gemma_Base       mistral_Base   -0.0136 0.0000 -0.0182 -0.0090    True\n",
      "      gemma_French       gemma_German   -0.1090 0.0000 -0.1285 -0.0895    True\n",
      "      gemma_French   gemma_Portuguese    0.0530 0.0000  0.0316  0.0744    True\n",
      "      gemma_French      gemma_Spanish    0.0341 0.0021  0.0015  0.0666    True\n",
      "      gemma_French      gpt3.5_French    0.0578 0.0000  0.0374  0.0782    True\n",
      "      gemma_French        gpt4_French    0.0632 0.0000  0.0426  0.0838    True\n",
      "      gemma_French       llama_French   -0.3083 0.0000 -0.3300 -0.2865    True\n",
      "      gemma_French     mistral_French   -0.1105 0.0000 -0.1404 -0.0805    True\n",
      "      gemma_German   gemma_Portuguese    0.1620 0.0000  0.1417  0.1823    True\n",
      "      gemma_German      gemma_Spanish    0.1430 0.0000  0.1111  0.1749    True\n",
      "      gemma_German      gpt3.5_German    0.0360 0.0000  0.0168  0.0553    True\n",
      "      gemma_German        gpt4_German    0.0276 0.0000  0.0082  0.0470    True\n",
      "      gemma_German       llama_German   -0.2448 0.0000 -0.2622 -0.2275    True\n",
      "      gemma_German     mistral_German   -0.1010 0.0000 -0.1236 -0.0783    True\n",
      "  gemma_Portuguese      gemma_Spanish   -0.0189 0.7628 -0.0520  0.0141   False\n",
      "  gemma_Portuguese  gpt3.5_Portuguese    0.0917 0.0000  0.0686  0.1147    True\n",
      "  gemma_Portuguese    gpt4_Portuguese    0.0939 0.0000  0.0708  0.1170    True\n",
      "  gemma_Portuguese   llama_Portuguese   -0.0889 0.0000 -0.1284 -0.0493    True\n",
      "  gemma_Portuguese mistral_Portuguese   -0.0805 0.0000 -0.1173 -0.0437    True\n",
      "     gemma_Spanish     gpt3.5_Spanish    0.1012 0.0000  0.0610  0.1414    True\n",
      "     gemma_Spanish       gpt4_Spanish    0.0908 0.0000  0.0506  0.1310    True\n",
      "     gemma_Spanish      llama_Spanish   -0.2202 0.0000 -0.2869 -0.1535    True\n",
      "     gemma_Spanish    mistral_Spanish   -0.0509 0.0695 -0.1117  0.0100   False\n",
      "       gpt3.5_Base      gpt3.5_French    0.0161 0.0010  0.0012  0.0309    True\n",
      "       gpt3.5_Base      gpt3.5_German   -0.1146 0.0000 -0.1293 -0.1000    True\n",
      "       gpt3.5_Base  gpt3.5_Portuguese    0.1030 0.0000  0.0856  0.1204    True\n",
      "       gpt3.5_Base     gpt3.5_Spanish    0.0935 0.0000  0.0651  0.1219    True\n",
      "       gpt3.5_Base          gpt4_Base    0.0207 0.0000  0.0146  0.0268    True\n",
      "       gpt3.5_Base         llama_Base   -0.0114 0.0000 -0.0166 -0.0063    True\n",
      "       gpt3.5_Base       mistral_Base   -0.0311 0.0000 -0.0363 -0.0259    True\n",
      "     gpt3.5_French      gpt3.5_German   -0.1307 0.0000 -0.1509 -0.1106    True\n",
      "     gpt3.5_French  gpt3.5_Portuguese    0.0869 0.0000  0.0647  0.1091    True\n",
      "     gpt3.5_French     gpt3.5_Spanish    0.0775 0.0000  0.0460  0.1089    True\n",
      "     gpt3.5_French        gpt4_French    0.0054 1.0000 -0.0151  0.0259   False\n",
      "     gpt3.5_French       llama_French   -0.3661 0.0000 -0.3876 -0.3445    True\n",
      "     gpt3.5_French     mistral_French   -0.1683 0.0000 -0.1981 -0.1384    True\n",
      "     gpt3.5_German  gpt3.5_Portuguese    0.2176 0.0000  0.1955  0.2397    True\n",
      "     gpt3.5_German     gpt3.5_Spanish    0.2082 0.0000  0.1767  0.2396    True\n",
      "     gpt3.5_German        gpt4_German   -0.0085 0.9942 -0.0287  0.0117   False\n",
      "     gpt3.5_German       llama_German   -0.2809 0.0000 -0.2991 -0.2626    True\n",
      "     gpt3.5_German     mistral_German   -0.1370 0.0000 -0.1604 -0.1137    True\n",
      " gpt3.5_Portuguese     gpt3.5_Spanish   -0.0095 1.0000 -0.0422  0.0233   False\n",
      " gpt3.5_Portuguese    gpt4_Portuguese    0.0022 1.0000 -0.0218  0.0262   False\n",
      " gpt3.5_Portuguese   llama_Portuguese   -0.1806 0.0000 -0.2206 -0.1405    True\n",
      " gpt3.5_Portuguese mistral_Portuguese   -0.1722 0.0000 -0.2096 -0.1349    True\n",
      "    gpt3.5_Spanish       gpt4_Spanish   -0.0104 1.0000 -0.0498  0.0291   False\n",
      "    gpt3.5_Spanish      llama_Spanish   -0.3214 0.0000 -0.3877 -0.2551    True\n",
      "    gpt3.5_Spanish    mistral_Spanish   -0.1520 0.0000 -0.2124 -0.0917    True\n",
      "         gpt4_Base        gpt4_French    0.0008 1.0000 -0.0147  0.0162   False\n",
      "         gpt4_Base        gpt4_German   -0.1438 0.0000 -0.1591 -0.1286    True\n",
      "         gpt4_Base    gpt4_Portuguese    0.0844 0.0000  0.0667  0.1022    True\n",
      "         gpt4_Base       gpt4_Spanish    0.0624 0.0000  0.0339  0.0910    True\n",
      "         gpt4_Base         llama_Base   -0.0322 0.0000 -0.0382 -0.0262    True\n",
      "         gpt4_Base       mistral_Base   -0.0518 0.0000 -0.0579 -0.0458    True\n",
      "       gpt4_French        gpt4_German   -0.1446 0.0000 -0.1651 -0.1240    True\n",
      "       gpt4_French    gpt4_Portuguese    0.0837 0.0000  0.0613  0.1061    True\n",
      "       gpt4_French       gpt4_Spanish    0.0617 0.0000  0.0301  0.0933    True\n",
      "       gpt4_French       llama_French   -0.3715 0.0000 -0.3933 -0.3496    True\n",
      "       gpt4_French     mistral_French   -0.1737 0.0000 -0.2037 -0.1437    True\n",
      "       gpt4_German    gpt4_Portuguese    0.2283 0.0000  0.2060  0.2506    True\n",
      "       gpt4_German       gpt4_Spanish    0.2063 0.0000  0.1748  0.2378    True\n",
      "       gpt4_German       llama_German   -0.2724 0.0000 -0.2909 -0.2540    True\n",
      "       gpt4_German     mistral_German   -0.1285 0.0000 -0.1520 -0.1050    True\n",
      "   gpt4_Portuguese       gpt4_Spanish   -0.0220 0.4238 -0.0547  0.0107   False\n",
      "   gpt4_Portuguese   llama_Portuguese   -0.1828 0.0000 -0.2228 -0.1427    True\n",
      "   gpt4_Portuguese mistral_Portuguese   -0.1744 0.0000 -0.2118 -0.1370    True\n",
      "      gpt4_Spanish      llama_Spanish   -0.3110 0.0000 -0.3773 -0.2447    True\n",
      "      gpt4_Spanish    mistral_Spanish   -0.1417 0.0000 -0.2020 -0.0813    True\n",
      "        llama_Base       llama_French   -0.3385 0.0000 -0.3551 -0.3220    True\n",
      "        llama_Base       llama_German   -0.3841 0.0000 -0.3961 -0.3720    True\n",
      "        llama_Base   llama_Portuguese   -0.0662 0.0000 -0.1027 -0.0296    True\n",
      "        llama_Base      llama_Spanish   -0.2164 0.0000 -0.2769 -0.1559    True\n",
      "        llama_Base       mistral_Base   -0.0197 0.0000 -0.0248 -0.0146    True\n",
      "      llama_French       llama_German   -0.0455 0.0000 -0.0654 -0.0257    True\n",
      "      llama_French   llama_Portuguese    0.2724 0.0000  0.2327  0.3121    True\n",
      "      llama_French      llama_Spanish    0.1221 0.0000  0.0597  0.1846    True\n",
      "      llama_French     mistral_French    0.1978 0.0000  0.1670  0.2286    True\n",
      "      llama_German   llama_Portuguese    0.3179 0.0000  0.2798  0.3561    True\n",
      "      llama_German      llama_Spanish    0.1677 0.0000  0.1062  0.2291    True\n",
      "      llama_German     mistral_German    0.1439 0.0000  0.1220  0.1657    True\n",
      "  llama_Portuguese      llama_Spanish   -0.1503 0.0000 -0.2204 -0.0801    True\n",
      "  llama_Portuguese mistral_Portuguese    0.0083 1.0000 -0.0408  0.0575   False\n",
      "     llama_Spanish    mistral_Spanish    0.1693 0.0000  0.0891  0.2495    True\n",
      "      mistral_Base     mistral_French   -0.1211 0.0000 -0.1476 -0.0946    True\n",
      "      mistral_Base     mistral_German   -0.2205 0.0000 -0.2395 -0.2016    True\n",
      "      mistral_Base mistral_Portuguese   -0.0381 0.0003 -0.0717 -0.0046    True\n",
      "      mistral_Base    mistral_Spanish   -0.0274 0.9111 -0.0814  0.0265   False\n",
      "    mistral_French     mistral_German   -0.0995 0.0000 -0.1316 -0.0674    True\n",
      "    mistral_French mistral_Portuguese    0.0829 0.0000  0.0406  0.1253    True\n",
      "    mistral_French    mistral_Spanish    0.0937 0.0000  0.0340  0.1533    True\n",
      "    mistral_German mistral_Portuguese    0.1824 0.0000  0.1443  0.2205    True\n",
      "    mistral_German    mistral_Spanish    0.1931 0.0000  0.1363  0.2500    True\n",
      "mistral_Portuguese    mistral_Spanish    0.0107 1.0000 -0.0523  0.0737   False\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\n=== POST-HOC TEST: Tukey's HSD ===\")\n",
    "tukey_results = pairwise_tukeyhsd(\n",
    "    df_anova[\"similarity\"],\n",
    "    df_anova[\"actor1\"] + \"_\" + df_anova[\"language\"],\n",
    "    alpha=0.005,\n",
    "    use_var=\"unequal\",\n",
    ")\n",
    "\n",
    "tukey_df = pd.DataFrame(\n",
    "    tukey_results._results_table.data[1:],  # type: ignore[attr-defined]\n",
    "    columns=tukey_results._results_table.data[0],  # type: ignore[attr-defined]\n",
    ")\n",
    "tukey_df[[\"model1\", \"language1\"]] = tukey_df[\"group1\"].str.split(\"_\", n=1, expand=True)\n",
    "tukey_df[[\"model2\", \"language2\"]] = tukey_df[\"group2\"].str.split(\"_\", n=1, expand=True)\n",
    "filtered_tukey = tukey_df[\n",
    "    (tukey_df[\"model1\"] == tukey_df[\"model2\"])\n",
    "    | (tukey_df[\"language1\"] == tukey_df[\"language2\"])\n",
    "]\n",
    "print(\n",
    "    filtered_tukey[\n",
    "        [\"group1\", \"group2\", \"meandiff\", \"p-adj\", \"lower\", \"upper\", \"reject\"]\n",
    "    ].to_string(index=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
